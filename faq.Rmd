---
title: "Frequently Asked Questions"
output: 
  html_document:
    toc:  true
    toc_float: true
---

<script>
function showHide(element) {
    var x = document.getElementById(element);
    if (x.style.display === "none") {
        x.style.display = "block";
    } else {
        x.style.display = "none";
    }
}
</script>

---

Below you can find a list of frequently asked questions, organized by topic, that reach us via email. Click the question to see our response.

---

### Time-varying covariates

---

<div onclick="showHide('faq1')" style="cursor: pointer; font-weight:bold">How do I include time-varying covariates with the RI-CLPM?</div>

<div id="faq1" style="display:none">
Time-varying covariates (TVC; $Z$) can be included like “regular” X and Y outcomes in the RI-CLPM; hence, rather than a bivariate RI-CLPM you would specify a tri- or more-variate RI-CLPM. As such, you decompose the TVCs in within-components (e.g. $wz1$, $wz2$, etc.) and a between-component (the random intercept; e.g. $RI_{z}$) and model these components separately. However, if you want to control for many TVC's, this can quickly become an unwieldly model, so researchers should think carefully about which TVC's they want to control for. </div>

---

<div onclick="showHide('faq3')" style="cursor: pointer; font-weight:bold">Is it possible to run an RI-CLPM with three (or more) outcomes?</div>
 
<div id="faq3" style="display:none">
Yes, it is statistically possible to run a “trivariate” RI-CLPM and empirical researchers have done so, see for example [Burns, Crisp, and [Van Lissa et al. (2019)](https://doi.org/10.1037/dev0000612). We don’t provide model code here for this mode, but extension to a trivariate RI-CLPM should be relatively straight forwards. That is, all variables should be decomponsed into between- (random intercepts) and within-components, and relevant lagged effects, as well as (residual) variances and covariances, should be included in the model.</div>

---

### Standardization

---

<div onclick="showHide('faq4')" style="cursor: pointer; font-weight:bold">How should I interpret the standardized cross-lagged and autoregressive parameters?</div>
 
<div id="faq4" style="display:none">
In the RI-CLPM, the standardized effects are reflective/representative of how much within-person variance in $y_{t}$ is *uniquely* explained (i.e., not also explained by other predictors) by the predictor $x_{t-1}$. Please note that this does not imply that one can make a one-on-one comparison with the percentage of explained variance. However, the standardized effects can be used to compare which effect is relatively stronger [(Schuurman, Ferrer, Boer-Sonnenschein, & Hamaker, 2016)](https://doi.org/10.1037/met0000062). </div>

---

<div onclick="showHide('faq5')" style="cursor: pointer; font-weight:bold">How do standardized cross-lagged and autoregressive parameters compare to explained variance?</div>
 
<div id="faq5" style="display:none">
The standardized lagged parameters are not equal to the (squared) semipartial correlation. Only under special circumstances, a standardized regression coefficient is equal to the pairwise correlation between the outcome and predictor, and the square of the standardized regression coefficient would then be the explained variance ($R^{2}$). This only applies in the case of (a) a simple regression, where there is only one predictor in the model, or (b) a multiple regression where the predictors are independent of each other. In the RI-CLPM, however, the multiple predictors are not independent of each other, and therefore the standardized regression coefficients are not equal to the pairwise correlation, (semi)partial correlation, or the unique explained variance. 

However, the standardized coefficient is closely related to the semipartial correlation, as demonstrated in footnote 3 of [Schuurman, Ferrer, Boer-Sonnenschein, and Hamaker (2016)](https://doi.org/10.1037/met0000062). The standardized coefficient is expressed in terms of pairwise correlations in the first equation there, and the semipartial correlation expressed in terms of pairwise correlations in the second equation. They are very similar, but there is a subtle difference in the denominator.
 
So, the semipartial correlation and standardized coefficient are not equal, but we can see that if the semipartical correlation for one predictor is larger than for another predictor, this will also be the case for the standardized coefficients of these predictors. The square of the semi-partial correlation is the *unique* explained variance, so we also know that the predictor with the largest standardized coefficient, will also have the largest *unique* explained variance. 

*Answer by [Dr. Noémi Schuurman](https://www.uu.nl/staff/NKSchuurman).*</div>

---

### Non-continuous outcomes

---

<div onclick="showHide('faq2')" style="cursor: pointer; font-weight:bold">Can I run the RI-CLPM with binary/categorical/count outcomes? </div>
 
<div id="faq2" style="display:none">
The RI-CLPM is currently only well-studied/well-developed for the continuous case. Research into RI-CLPMs with only categorical data, or with non-commensurate outcomes (i.e., outcomes measured in different scales, continuous and binary) is still ongoing. See, for example, [the Mplus discussion board](http://www.statmodel.com/discussion/messages/23/23001.html?1530924636). </div>

---

### Time & time-lags

---

<div onclick="showHide('faq6')" style="cursor: pointer; font-weight:bold">How to deal with unequal intervals between repeated measures?</div>

<div id="faq6" style="display:none">
The lagged regression coefficients depend on the time lag between repeated measures (in a non-linear way). If the lags between subsequent occasions vary, qualitatively different autoregressive and cross-lagged effects between each pair of adjacent measurements are estimated. The advice is to **not** constrain these parameters over time in this case, as this would lead to an uninterpretable blend of different lagged relationships. Neither should the residual variances and covariances (of the within-components) be constrained to be invariant over time, as these also depend on the interval between measurements. </div>

--- 

### Power

---
<div onclick="showHide('faq8')" style="cursor: pointer; font-weight:bold">How do I perform a power analysis for the RI-CLPM?</div>

<div id="faq8" style="display:none">We have developed an alpha version of the `powRICLPM`-package for performing power analyses for the RI-CLPM in R. It is not available for download yet because we are currently still testing it. If, however, you would like to perform a power analysis for the RI-CLPM, please contact [Jeroen Mulder](mailto:j.d.mulder@uu.nl). We might then be able to kill 2 birds with 1 stone: You get a power analysis, and we get an empirical test case. 

You can also perform a power analysis using the [MONTECARLO functionality of Mplus](https://www.statmodel.com/download/usersguide/Chapter12.pdf).</div>

---

### CLPM v. RICLPM

---

<div onclick="showHide('faq9')" style="cursor: pointer; font-weight:bold">Why are the autoregressive effects in the RI-CLPM typically smaller than in the CLPM?</div>

<div id="faq9" style="display:none">The autoregressive effects in the CLPM and the RI-CLPM capture two distinct phenomena. In the traditional CLPM, the autoregressive effects capture both within- and between-unit effects, and it can be interpreted as rank-order stability. In the RI-CLPM, the stable, between-person variance is separated from the within-person variance such that the autoregressive effects only capture within-person carry-over. In other words, in the RI-CLPM the autoregressive effects are typically smaller because the stable, trait-like stability is not captured anymore by the autoregressive effects (as in the CLPM), but by the random intercepts.</div>

---

<div onclick="showHide('faq10')" style="cursor: pointer; font-weight:bold">Is it a bad sign that the standard errors are typically larger in the RI-CLPM than in the CLPM?</div>

<div id="faq10" style="display:none">No, this is to be expected because the RI-CLPM is a more complex model than the CLPM. Therefore, the point estimates are less certain, but this does not imply that the estimates are biased and the model does not give us any insight in the underlying mechanism under study. In contrast, the RI-CLPM is likely less biased than results from the CLPM because the RI-CLM accounts for stable, unobserved factors that create lasting between-person differences, which can create spurious empirical relationships between the constructs under investigation when not properly accounted for.</div>

---

### Response to Orth et al. (2021)

Lately, we have received numerous questions about statements regarding the use and appropriateness of the CLPM and RI-CLPM in "Testing Prospective Effects in Longitudinal Research: Comparing Seven Competing Cross-Lagged Models" by [Orth et al. (2021)](http://dx.doi.org/10.1037/pspp0000358). In our opinion, numerous conclusions herein are unwarranted, and we therefore feel compelled to provide an informal response to some of their most prominent statements below. 

---

<div onclick="showHide('faq11')" style="cursor: pointer; font-weight:bold">The RI-CLPM is not suited for studying prospective between-person effects, whereas the CLPM is.</div>

<div id="faq11" style="display:none">
On page 1026, Orth et al. (2020) state that the RI-CLPM does not allow for the testing of prospective between-person effects because "(...) *the random intercept factors provide information only about correlational associations between the constructs* (...)*, but not about time-lagged (i.e, longitudinal) and directional between-person effects.*" It is true that the RI-CLPM separates stable, between-person differences from temporal, within-person fluctuations. Only the latter allow one to look at prospective effects over time, while the stable between-person differences have not particular time-order.

The reasoning that Orth et al. seem to follow is this: If one is interested in trait-changes, we should not separate the stable trait components from the temporary fluctuations, as the first does not allow for the study of prospective effects and are not of interest because they are entirely stable, while the latter only contain state-like fluctuations that are less interesting to researchers who want to study in trait-changes. Orth et al. seem to consider both components not to be of interest, but instead somehow propose that a blend of both components is the key issue of interest. We strongly believe this is incorrect.

Researchers who want to use prospective effects to study certain psychological processes, should make sure that their measurements are obtained at the time scale at which they believe the process of interest operates. If the trait-changes of interest are assumed to take place from one year to the next, then measuring yearly over several years should capture the fluctuations of interest within persons over the time span covered by the study. If trait-changes are assumed to take place at a less fine time scale such as from decade to decade, this implies researchers should obtain data measured once per decade for several decades. 

Even when one is not interested in such cases in the stable between-person differences, these need to be separated from the within-person fluctuations. The stable mean differences between persons are often referred to as trait differences, but may also be conceptualized as resulting from stable confounders such as stable genetic and environmental factors that affect our measurements.      
In sum, the focus should be on how the constructs are measured, specifically their time scale. By definition, the random intercepts in the RI-CLPM capture variance that is stable over the duration of the study, which is why—from a data analytical perspective—these are referred to as traits. The remainder of the variance is what varies within persons over time, which is why—again from a data analytical perspective—these it is referred to as states. These trait-like between-person differences and state-like, within-person fluctuations need not coincide perfectly with the trait-state distinction made by substantive researchers. Nevertheless, it is essential to separate these two sources, regardless of what they are called.</div>

---

<div onclick="showHide('faq12')" style="cursor: pointer; font-weight:bold">The RI-CLPM is better suited for short-term studies because it cannot detect sustained prospective effects.</div>

<div id="faq12" style="display:none">The characterization of the lagged effects as short- or long-term depends on the time scale at which the measurements are made. When using annual data, lagged effects capture the fluctuation from year to year; when dealing with data that were obtained every decade, the within-person fluctuations will concern the changes from decade to decade. It is all relative to how the data were measured, and even when we are focusing on trait changes by measuring people once every 10 years, for say 40 years, there will still be stable between-person differences between individuals that need to be controlled for.

Hence, the need to decompose the observations into a stable between-person component and temporal within-person components is independent of the time scale at which measurements were obtained.</div> 

---

<div onclick="showHide('faq13')" style="cursor: pointer; font-weight:bold">There should be a match between the type of research question asked and the model used: The CLPM is for the analysis of between-person prospective effects whereas the RI-CLPM should be used for within-person prospective effects.</div>

<div id="faq13" style="display:none">We agree with the authors in so far that there should be a match between the research question and the statistical model used. However, the critical distinction here is not whether one is interested in within-person or between-person prospective effects (as argued above, the RI-CLPM can capture trait-changes depending on the time scale at which measurements are gathered). Rather, we should distinguish between descriptive, predictive, and causal research questions (cf., [Hamaker, Mulder, and Van IJzendoorn, 2020](https://doi.org/10.1016/j.dcn.2020.100867)). The CLPM is suitable for predictive research questions: e.g., "Who is at risk for heightened $X$?" and "Who should get an intervention to reduce $Y$?". However, for answering causal research questions, other models should be used, because the CLPM does not control for stable, between-person difference. This is problematic as failing to properly account for such confounding effects can lead to finding spurious lagged effects, a failure to find true relationships, or more generally, biased estimates ([Hamaker, Kuiper, & Grasman, 2015](https://doi.org/10.1037/a0038889)).</div>

---

<div onclick="showHide('faq14')" style="cursor: pointer; font-weight:bold">The parameters from the CLPM tend to have smaller standard errors than the parameters from the RI-CLPM; hence, the results from the CLPM are easier to replicate, which may be a reason to prefer this model.</div>

<div id="faq14" style="display:none">
On page 1028, Orth et al. state that "For the CLPM, the structural coefficients were much more consistent compared to the RI-CLPM, both across and within samples, which is important with regard to replicability of research findings (Asendorf et al., 2013). Even if theoretical consideration have priority over replicability in model selection, replicability of estimates is---other things being equal---an important criterion of the quality of statistical models."

When the goal is prediction, this may indeed be an important consideration. However, when the goal is to gain insight in the underlying mechanism, we should not prefer a model based on its ability to replicate results: Replicating erroneous results is not helping us. Instead, we should consider which model seems more reasonable (e.g., do we believe there may be unobserved, stable confounding that plays a role in our measurements), and which model provides a better description of the data (i.e., can we use the chi-square difference test, or information criteria to compare competing models).

The larger standard errors associated with the RI-CLPM imply that if we want to have the same precision, we need to obtain data from larger samples and/or at more waves.</div> 



